# ğŸ“ Student Performance Prediction â€” Complete Machine Learning Project  
*End-to-end regression pipeline with PCA, From-Scratch Algorithms, Boosting, SVM, and Stacking*

This project predicts a student's **Performance Index** using a full machine learning workflow.  
The goal is to demonstrate **deep ML understanding**, not deployment â€” including:

## ğŸ“˜ Project Highlights

- End-to-end ML workflow with clean modular structure  
- PCA-based dimensionality reduction  
- From-scratch ML implementations for deeper understanding  
- Multiple sklearn models for comparison  
- Boosting and stacking ensembles  
- Strong result evaluation with RÂ², MSE, and visual analysis  
- Organized outputs: results, plots, predictions, models, processed data  


---

## ğŸ“˜ Dataset
**Student Performance Dataset**  
ğŸ”— https://www.kaggle.com/datasets/nikhil7280/student-performance-multiple-linear-regression

**Target Variable:** `Performance_Index`

---

## ğŸ§  Algorithms Implemented

<div style="display: flex; gap: 40px;">

<div style="flex: 1;">

### ğŸŸ¦ From Scratch  
- Linear Regression  
- k-Nearest Neighbors  
- Support Vector Regression  
- Manual Stacking  

</div>

<div style="flex: 1;">

### ğŸŸ© Using Sklearn  
- Linear Regression  
- Ridge & Lasso  
- KNN Regressor  
- Decision Tree  
- SVR (RBF Kernel)  
- AdaBoost  
- Gradient Boosting  
- Stacking Regressor  

</div>

</div>


---

## ğŸ“‚ Project Structure

To keep the repository clean and easy to navigate, files are grouped into logical folders:

- ğŸ“˜ **Notebook** â†’ [`notebook/student_performance_ml_project.ipynb`](notebook/)
- ğŸ“Š **Results** (metrics, comparison tables) â†’ [`results/`](results/)
- ğŸ“ˆ **Plots** (visual outputs) â†’ [`plots/`](plots/)
- ğŸ“„ **Predictions** â†’ [`predictions/`](predictions/)
- ğŸ—‚ **Raw Data** â†’ [`data_raw/`](data_raw/)
- ğŸ§® **Processed Data** â†’ [`data_processed/`](data_processed/)
- ğŸ”§ **Models & Encoders** â†’ [`models/`](models/)
- ğŸ“¦ **All Outputs ZIP** â†’ [`student_performance_project_outputs.zip`](student_performance_project_outputs.zip)

> âœ” This keeps the README clean  
> âœ” Readers can navigate instantly with links  
> âœ” Avoids long directory trees that clutter the page  


---

## ğŸ“ˆ Visualizations Included

- Heatmap of correlations  
- PCA explained variance plot  
- Actual vs Predicted (best model)  
- Model comparison bar chart  
- Error distribution plot  

All available inside the `plots/` folder.

---
## ğŸ“Š Results Summary

After evaluating all models across MSE and RÂ² metrics, the **Stacking Regressor (Sklearn)** delivered the best overall performance.

### â­ Best Model: Stacking Regressor (Sklearn)
- **Highest RÂ² Score** (~0.90 depending on run)
- **Lowest Mean Squared Error**
- **Most stable and consistent predictions**

### ğŸ” Key Insights from Model Comparison
- **Boosting models** (Gradient Boosting, AdaBoost) performed significantly better than single weak learners.
- **Regularized Linear Models** (Ridge & Lasso) showed improvement over standard Linear Regression.
- **From-Scratch Models** (kNN, Linear Regression, SVR) closely matched sklearn performance, validating correctness.
- **PCA** reduced dimensionality while maintaining predictive power, improving model stability.

Detailed metrics for all models are available in the [`results/`](results/) directory.  
Visual comparisons (bar charts, error distributions, predictions vs actual) are in [`plots/`](plots/).

See:  
ğŸ“„ `final_model_summary_with_rank.csv`  
ğŸ“Š `plot_model_comparison.png`

---
## â–¶ï¸ How to Run the Project

### 1ï¸âƒ£ Set up the environment
Create and activate a virtual environment (recommended):

```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# Mac / Linux
source .venv/bin/activate
```
install all requiered dependencies- 
```
pip install -r requirements.txt
```
### 2ï¸âƒ£ Run the notebook-
`jupyter notebook notebook/student_performance_ml_project.ipynb`
### 3ï¸âƒ£ Project File Paths (auto-recognized)

The notebook automatically loads and saves files in the following folders:

- **data_raw/** â€” raw dataset  
- **data_processed/** â€” scaled data, PCA outputs  
- **plots/** â€” all visualizations and graphs  
- **predictions/** â€” model prediction CSVs  
- **results/** â€” evaluation metrics, comparison tables  
- **models/** â€” encoders, scaler, and saved preprocessing objects  
No manual path changes are required.

### 4ï¸âƒ£ (Optional) Reproduce Everything Automatically

If you have **papermill** installed, you can regenerate all results, plots, and outputs with a single command:

`bash
./run_all.sh`
This will create a fully executed notebook at: **notebook/executed_student_performance.ipynb** 


---

### 5ï¸âƒ£ (Optional) Run in Google Colab

```markdown

1. Open Google Colab  
2. Upload the main notebook:  **notebook/student_performance_ml_project.ipynb**
3. Upload the **data_raw/** folder  
4. Run all cells
```
All other folders (`data_processed`, `plots`, `models`, etc.) will be created automatically by the notebook.



## ğŸ§  Key Learnings Demonstrated

<div style="display: flex; gap: 40px;">

<div style="flex: 1;">

### ğŸ”¹ Data Processing & Preparation  
- Categorical encoding  
- Scaling and normalization  
- PCA dimensionality reduction  
- Clean handling of training/testing sets  
- Organized saving of processed data  

### ğŸ”¹ From-Scratch ML  
- Linear Regression using matrix algebra  
- kNN using distance computation  
- SVR with simplified gradient updates  
- Manual stacking using meta-learners  

</div>

<div style="flex: 1;">

### ğŸ”¹ Model Training & Evaluation  
- Regression models (Linear, Ridge, Lasso)  
- Tree-based and boosting models  
- SVM with RBF kernel  
- Ensemble stacking (sklearn + manual)  
- RÂ², MSE evaluation metrics  
- Error distribution & prediction analysis  
- Final model ranking & comparison  

</div>

</div>
  

This project reflects depth of understanding, not just model usage.


### Install required libraries:
`bash pip install -r requirements.txt 


## ğŸš€ Future Work

Here are several extensions planned for the next iteration:

- Hyperparameter tuning with GridSearchCV / Optuna  
- Adding Random Forest / XGBoost / LightGBM  
- Feature importance analysis using SHAP  
- Cross-validation pipelines  
- Outlier detection and data quality checks  
- Interactive dashboard using Streamlit  
- Model deployment (FastAPI + Docker)  

## ğŸ‘¤ Author

**Ankush Patil**  
ğŸ“ India  

ğŸ“§ Email: ankpatil1203@gmail.com
ğŸ”— LinkedIn: https://www.linkedin.com/in/ankush-patil-48989739a
ğŸ™ GitHub: https://github.com/Ankush-Patil99  

Feel free to reach out for collaborations or suggestions.

